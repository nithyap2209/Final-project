{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Sales Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = pd.read_csv(r\"C:\\Users\\Selvam\\OneDrive\\Desktop\\project\\Sales_Forecasting\\Sales Forecasting\\stores.csv\")\n",
    "features = pd.read_csv(r\"C:\\Users\\Selvam\\OneDrive\\Desktop\\project\\Sales_Forecasting\\Sales Forecasting\\features.csv\")\n",
    "train = pd.read_csv(r\"C:\\Users\\Selvam\\OneDrive\\Desktop\\project\\Sales_Forecasting\\Sales Forecasting\\train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the first few rows of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store Type    Size\n",
      "0      1    A  151315\n",
      "1      2    A  202307\n",
      "2      3    B   37392\n",
      "3      4    A  205863\n",
      "4      5    B   34875\n",
      "   Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
      "0      1  2010-02-05        42.31       2.572        NaN        NaN   \n",
      "1      1  2010-02-12        38.51       2.548        NaN        NaN   \n",
      "2      1  2010-02-19        39.93       2.514        NaN        NaN   \n",
      "3      1  2010-02-26        46.63       2.561        NaN        NaN   \n",
      "4      1  2010-03-05        46.50       2.625        NaN        NaN   \n",
      "\n",
      "   MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
      "0        NaN        NaN        NaN  211.096358         8.106      False  \n",
      "1        NaN        NaN        NaN  211.242170         8.106       True  \n",
      "2        NaN        NaN        NaN  211.289143         8.106      False  \n",
      "3        NaN        NaN        NaN  211.319643         8.106      False  \n",
      "4        NaN        NaN        NaN  211.350143         8.106      False  \n",
      "   Store  Dept        Date  Weekly_Sales  IsHoliday\n",
      "0      1     1  2010-02-05      24924.50      False\n",
      "1      1     1  2010-02-12      46039.49       True\n",
      "2      1     1  2010-02-19      41595.55      False\n",
      "3      1     1  2010-02-26      19403.54      False\n",
      "4      1     1  2010-03-05      21827.90      False\n"
     ]
    }
   ],
   "source": [
    "print(stores.head())\n",
    "print(features.head())\n",
    "print(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on 'Store' and 'Date'\n",
    "data = train.merge(stores, on='Store')\n",
    "data = data.merge(features, on=['Store', 'Date', 'IsHoliday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store  Dept        Date  Weekly_Sales  IsHoliday Type    Size  Temperature  \\\n",
      "0      1     1  2010-02-05      24924.50      False    A  151315        42.31   \n",
      "1      1     2  2010-02-05      50605.27      False    A  151315        42.31   \n",
      "2      1     3  2010-02-05      13740.12      False    A  151315        42.31   \n",
      "3      1     4  2010-02-05      39954.04      False    A  151315        42.31   \n",
      "4      1     5  2010-02-05      32229.38      False    A  151315        42.31   \n",
      "\n",
      "   Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
      "0       2.572        NaN        NaN        NaN        NaN        NaN   \n",
      "1       2.572        NaN        NaN        NaN        NaN        NaN   \n",
      "2       2.572        NaN        NaN        NaN        NaN        NaN   \n",
      "3       2.572        NaN        NaN        NaN        NaN        NaN   \n",
      "4       2.572        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "          CPI  Unemployment  \n",
      "0  211.096358         8.106  \n",
      "1  211.096358         8.106  \n",
      "2  211.096358         8.106  \n",
      "3  211.096358         8.106  \n",
      "4  211.096358         8.106  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the merged dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store                0\n",
      "Dept                 0\n",
      "Weekly_Sales         0\n",
      "IsHoliday            0\n",
      "Type                 0\n",
      "Size                 0\n",
      "Temperature          0\n",
      "Fuel_Price           0\n",
      "MarkDown1       270889\n",
      "MarkDown2       310322\n",
      "MarkDown3       284479\n",
      "MarkDown4       286603\n",
      "MarkDown5       270138\n",
      "CPI                  0\n",
      "Unemployment         0\n",
      "Year                 0\n",
      "Month                0\n",
      "Day                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Date' to datetime type\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Extract year, month, and day from 'Date'\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Day'] = data['Date'].dt.day\n",
    "\n",
    "# Drop the 'Date' column as we have extracted useful features from it\n",
    "data = data.drop(columns=['Date'])\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Fill missing values for Markdown columns with 0 (assuming missing means no markdown)\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['Store', 'Dept', 'Type', 'IsHoliday']\n",
    "numerical_features = data.drop(columns=categorical_features + ['Weekly_Sales']).columns\n",
    "\n",
    "# Preprocessing pipelines for numerical and categorical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (337256, 17)\n",
      "Testing data shape: (84314, 17)\n"
     ]
    }
   ],
   "source": [
    "# Define features and target variable\n",
    "X = data.drop(columns=['Weekly_Sales'])\n",
    "y = data['Weekly_Sales']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only 50% of the data\n",
    "X_train_small, _, y_train_small, _ = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1))])\n",
    "\n",
    "model.fit(X_train_small, y_train_small)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "# Plot actual vs predicted sales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')\n",
    "plt.xlabel('Actual Sales')\n",
    "plt.ylabel('Predicted Sales')\n",
    "plt.title('Actual vs Predicted Sales')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
